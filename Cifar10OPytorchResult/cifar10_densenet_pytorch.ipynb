{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-yiw3drACcH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import densenet121, DenseNet121_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ5msX9RCKFx",
        "outputId": "c05c1c67-1c97-4d33-fcfa-e3e1511eea68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for data preprocessing\n",
        "normMean = [0.49139968, 0.48215827, 0.44653124]\n",
        "normStd = [0.24703233, 0.24348505, 0.26158768]\n",
        "normTransform = transforms.Normalize(normMean, normStd)\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      normTransform\n",
        "  ])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normTransform\n",
        "])\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=trainTransform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=testTransform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pre-trained DenseNet model\n",
        "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "def adjust_opt(optAlg, optimizer, epoch):\n",
        "    if optAlg == 'sgd':\n",
        "        if epoch < 150:\n",
        "            lr = 1e-1\n",
        "        elif epoch == 150:\n",
        "            lr = 1e-2\n",
        "        elif epoch == 225:\n",
        "            lr = 1e-3\n",
        "        else:\n",
        "            return\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "    return lr\n",
        "# Train the model\n",
        "for epoch in range(300):\n",
        "    lr = adjust_opt('sgd', optimizer, epoch)  # Adjust learning rate\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    # print every epoch\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {running_loss / i:.4f}, Accuracy: {100 * correct / total:.2f}%, lr: {lr:.4f}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# Test the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7qUQWbUATJL",
        "outputId": "2882cbaf-6081-4742-f3a3-e163bc86d113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 1, Loss: 2.9500, Accuracy: 21.31%, lr: 0.1000\n",
            "Epoch: 2, Loss: 1.7942, Accuracy: 33.26%, lr: 0.1000\n",
            "Epoch: 3, Loss: 1.6704, Accuracy: 37.59%, lr: 0.1000\n",
            "Epoch: 4, Loss: 1.5930, Accuracy: 40.65%, lr: 0.1000\n",
            "Epoch: 5, Loss: 1.5093, Accuracy: 44.18%, lr: 0.1000\n",
            "Epoch: 6, Loss: 1.4193, Accuracy: 48.53%, lr: 0.1000\n",
            "Epoch: 7, Loss: 1.3311, Accuracy: 52.10%, lr: 0.1000\n",
            "Epoch: 8, Loss: 1.2635, Accuracy: 54.99%, lr: 0.1000\n",
            "Epoch: 9, Loss: 1.2138, Accuracy: 56.60%, lr: 0.1000\n",
            "Epoch: 10, Loss: 1.2537, Accuracy: 55.10%, lr: 0.1000\n",
            "Epoch: 11, Loss: 1.1398, Accuracy: 59.15%, lr: 0.1000\n",
            "Epoch: 12, Loss: 1.0804, Accuracy: 61.35%, lr: 0.1000\n",
            "Epoch: 13, Loss: 1.0451, Accuracy: 62.67%, lr: 0.1000\n",
            "Epoch: 14, Loss: 0.9934, Accuracy: 64.78%, lr: 0.1000\n",
            "Epoch: 15, Loss: 0.9582, Accuracy: 66.34%, lr: 0.1000\n",
            "Epoch: 16, Loss: 0.9292, Accuracy: 67.62%, lr: 0.1000\n",
            "Epoch: 17, Loss: 0.9053, Accuracy: 68.38%, lr: 0.1000\n",
            "Epoch: 18, Loss: 0.8739, Accuracy: 69.37%, lr: 0.1000\n",
            "Epoch: 19, Loss: 0.8476, Accuracy: 70.40%, lr: 0.1000\n",
            "Epoch: 20, Loss: 0.8329, Accuracy: 71.13%, lr: 0.1000\n",
            "Epoch: 21, Loss: 0.8035, Accuracy: 72.03%, lr: 0.1000\n",
            "Epoch: 22, Loss: 0.7903, Accuracy: 72.53%, lr: 0.1000\n",
            "Epoch: 23, Loss: 0.7734, Accuracy: 72.90%, lr: 0.1000\n",
            "Epoch: 24, Loss: 0.7600, Accuracy: 73.70%, lr: 0.1000\n",
            "Epoch: 25, Loss: 0.7438, Accuracy: 74.11%, lr: 0.1000\n",
            "Epoch: 26, Loss: 0.7356, Accuracy: 74.44%, lr: 0.1000\n",
            "Epoch: 27, Loss: 0.7214, Accuracy: 75.10%, lr: 0.1000\n",
            "Epoch: 28, Loss: 0.7103, Accuracy: 75.20%, lr: 0.1000\n",
            "Epoch: 29, Loss: 0.6943, Accuracy: 75.89%, lr: 0.1000\n",
            "Epoch: 30, Loss: 0.6899, Accuracy: 76.11%, lr: 0.1000\n",
            "Epoch: 31, Loss: 0.6779, Accuracy: 76.58%, lr: 0.1000\n",
            "Epoch: 32, Loss: 0.6669, Accuracy: 76.54%, lr: 0.1000\n",
            "Epoch: 33, Loss: 0.6578, Accuracy: 77.11%, lr: 0.1000\n",
            "Epoch: 34, Loss: 0.6489, Accuracy: 77.62%, lr: 0.1000\n",
            "Epoch: 35, Loss: 0.6520, Accuracy: 77.24%, lr: 0.1000\n",
            "Epoch: 36, Loss: 0.6399, Accuracy: 77.91%, lr: 0.1000\n",
            "Epoch: 37, Loss: 0.6335, Accuracy: 77.95%, lr: 0.1000\n",
            "Epoch: 38, Loss: 0.6232, Accuracy: 78.43%, lr: 0.1000\n",
            "Epoch: 39, Loss: 0.6181, Accuracy: 78.51%, lr: 0.1000\n",
            "Epoch: 40, Loss: 0.6132, Accuracy: 78.78%, lr: 0.1000\n",
            "Epoch: 41, Loss: 0.6055, Accuracy: 79.01%, lr: 0.1000\n",
            "Epoch: 42, Loss: 0.5999, Accuracy: 79.26%, lr: 0.1000\n",
            "Epoch: 43, Loss: 0.5995, Accuracy: 79.30%, lr: 0.1000\n",
            "Epoch: 44, Loss: 0.5905, Accuracy: 79.67%, lr: 0.1000\n",
            "Epoch: 45, Loss: 0.5857, Accuracy: 79.78%, lr: 0.1000\n",
            "Epoch: 46, Loss: 0.5885, Accuracy: 79.47%, lr: 0.1000\n",
            "Epoch: 47, Loss: 0.5822, Accuracy: 79.96%, lr: 0.1000\n",
            "Epoch: 48, Loss: 0.5718, Accuracy: 80.20%, lr: 0.1000\n",
            "Epoch: 49, Loss: 0.5672, Accuracy: 80.47%, lr: 0.1000\n",
            "Epoch: 50, Loss: 0.5599, Accuracy: 80.64%, lr: 0.1000\n",
            "Epoch: 51, Loss: 0.5612, Accuracy: 80.52%, lr: 0.1000\n",
            "Epoch: 52, Loss: 0.5687, Accuracy: 80.50%, lr: 0.1000\n",
            "Epoch: 53, Loss: 0.5533, Accuracy: 81.01%, lr: 0.1000\n",
            "Epoch: 54, Loss: 0.5559, Accuracy: 80.83%, lr: 0.1000\n",
            "Epoch: 55, Loss: 0.5476, Accuracy: 81.17%, lr: 0.1000\n",
            "Epoch: 56, Loss: 0.5381, Accuracy: 81.56%, lr: 0.1000\n",
            "Epoch: 57, Loss: 0.5436, Accuracy: 81.20%, lr: 0.1000\n",
            "Epoch: 58, Loss: 0.5331, Accuracy: 81.55%, lr: 0.1000\n",
            "Epoch: 59, Loss: 0.5326, Accuracy: 81.57%, lr: 0.1000\n",
            "Epoch: 60, Loss: 0.5318, Accuracy: 81.62%, lr: 0.1000\n",
            "Epoch: 61, Loss: 0.5231, Accuracy: 81.96%, lr: 0.1000\n",
            "Epoch: 62, Loss: 0.5246, Accuracy: 81.90%, lr: 0.1000\n",
            "Epoch: 63, Loss: 0.5229, Accuracy: 81.80%, lr: 0.1000\n",
            "Epoch: 64, Loss: 0.5223, Accuracy: 81.93%, lr: 0.1000\n",
            "Epoch: 65, Loss: 0.5172, Accuracy: 82.13%, lr: 0.1000\n",
            "Epoch: 66, Loss: 0.5190, Accuracy: 82.17%, lr: 0.1000\n",
            "Epoch: 67, Loss: 0.5074, Accuracy: 82.34%, lr: 0.1000\n",
            "Epoch: 68, Loss: 0.5119, Accuracy: 82.36%, lr: 0.1000\n",
            "Epoch: 69, Loss: 0.5123, Accuracy: 82.33%, lr: 0.1000\n",
            "Epoch: 70, Loss: 0.5137, Accuracy: 82.13%, lr: 0.1000\n",
            "Epoch: 71, Loss: 0.5119, Accuracy: 82.32%, lr: 0.1000\n",
            "Epoch: 72, Loss: 0.5067, Accuracy: 82.39%, lr: 0.1000\n",
            "Epoch: 73, Loss: 0.5012, Accuracy: 82.54%, lr: 0.1000\n",
            "Epoch: 74, Loss: 0.4987, Accuracy: 82.84%, lr: 0.1000\n",
            "Epoch: 75, Loss: 0.4986, Accuracy: 82.66%, lr: 0.1000\n",
            "Epoch: 76, Loss: 0.4966, Accuracy: 82.81%, lr: 0.1000\n",
            "Epoch: 77, Loss: 0.4977, Accuracy: 82.99%, lr: 0.1000\n",
            "Epoch: 78, Loss: 0.4951, Accuracy: 82.92%, lr: 0.1000\n",
            "Epoch: 79, Loss: 0.4902, Accuracy: 83.00%, lr: 0.1000\n",
            "Epoch: 80, Loss: 0.4885, Accuracy: 82.97%, lr: 0.1000\n",
            "Epoch: 81, Loss: 0.4856, Accuracy: 83.06%, lr: 0.1000\n",
            "Epoch: 82, Loss: 0.4889, Accuracy: 83.04%, lr: 0.1000\n",
            "Epoch: 83, Loss: 0.4860, Accuracy: 83.18%, lr: 0.1000\n",
            "Epoch: 84, Loss: 0.4888, Accuracy: 83.08%, lr: 0.1000\n",
            "Epoch: 85, Loss: 0.4880, Accuracy: 83.12%, lr: 0.1000\n",
            "Epoch: 86, Loss: 0.4765, Accuracy: 83.69%, lr: 0.1000\n",
            "Epoch: 87, Loss: 0.4777, Accuracy: 83.42%, lr: 0.1000\n",
            "Epoch: 88, Loss: 0.4748, Accuracy: 83.47%, lr: 0.1000\n",
            "Epoch: 89, Loss: 0.4738, Accuracy: 83.54%, lr: 0.1000\n",
            "Epoch: 90, Loss: 0.4776, Accuracy: 83.62%, lr: 0.1000\n",
            "Epoch: 91, Loss: 0.4805, Accuracy: 83.23%, lr: 0.1000\n",
            "Epoch: 92, Loss: 0.4751, Accuracy: 83.57%, lr: 0.1000\n",
            "Epoch: 93, Loss: 0.4734, Accuracy: 83.53%, lr: 0.1000\n",
            "Epoch: 94, Loss: 0.4783, Accuracy: 83.39%, lr: 0.1000\n",
            "Epoch: 95, Loss: 0.4726, Accuracy: 83.58%, lr: 0.1000\n",
            "Epoch: 96, Loss: 0.4715, Accuracy: 83.67%, lr: 0.1000\n",
            "Epoch: 97, Loss: 0.4623, Accuracy: 83.97%, lr: 0.1000\n",
            "Epoch: 98, Loss: 0.4673, Accuracy: 83.85%, lr: 0.1000\n",
            "Epoch: 99, Loss: 0.4639, Accuracy: 83.89%, lr: 0.1000\n",
            "Epoch: 100, Loss: 0.4711, Accuracy: 83.61%, lr: 0.1000\n",
            "Epoch: 101, Loss: 0.4701, Accuracy: 83.81%, lr: 0.1000\n",
            "Epoch: 102, Loss: 0.4704, Accuracy: 83.78%, lr: 0.1000\n",
            "Epoch: 103, Loss: 0.4567, Accuracy: 84.28%, lr: 0.1000\n",
            "Epoch: 104, Loss: 0.4645, Accuracy: 83.96%, lr: 0.1000\n",
            "Epoch: 105, Loss: 0.4609, Accuracy: 84.05%, lr: 0.1000\n",
            "Epoch: 106, Loss: 0.4644, Accuracy: 83.99%, lr: 0.1000\n",
            "Epoch: 107, Loss: 0.4578, Accuracy: 84.27%, lr: 0.1000\n",
            "Epoch: 108, Loss: 0.4620, Accuracy: 83.88%, lr: 0.1000\n",
            "Epoch: 109, Loss: 0.4592, Accuracy: 84.13%, lr: 0.1000\n",
            "Epoch: 110, Loss: 0.4626, Accuracy: 83.98%, lr: 0.1000\n",
            "Epoch: 111, Loss: 0.4645, Accuracy: 83.97%, lr: 0.1000\n",
            "Epoch: 112, Loss: 0.4575, Accuracy: 84.15%, lr: 0.1000\n",
            "Epoch: 113, Loss: 0.4589, Accuracy: 83.93%, lr: 0.1000\n",
            "Epoch: 114, Loss: 0.4509, Accuracy: 84.42%, lr: 0.1000\n",
            "Epoch: 115, Loss: 0.4565, Accuracy: 84.26%, lr: 0.1000\n",
            "Epoch: 116, Loss: 0.4535, Accuracy: 84.26%, lr: 0.1000\n",
            "Epoch: 117, Loss: 0.4572, Accuracy: 84.16%, lr: 0.1000\n",
            "Epoch: 118, Loss: 0.4530, Accuracy: 84.25%, lr: 0.1000\n",
            "Epoch: 119, Loss: 0.4536, Accuracy: 84.32%, lr: 0.1000\n",
            "Epoch: 120, Loss: 0.4555, Accuracy: 84.12%, lr: 0.1000\n",
            "Epoch: 121, Loss: 0.4548, Accuracy: 84.24%, lr: 0.1000\n",
            "Epoch: 122, Loss: 0.4476, Accuracy: 84.52%, lr: 0.1000\n",
            "Epoch: 123, Loss: 0.4489, Accuracy: 84.42%, lr: 0.1000\n",
            "Epoch: 124, Loss: 0.4482, Accuracy: 84.52%, lr: 0.1000\n",
            "Epoch: 125, Loss: 0.4439, Accuracy: 84.71%, lr: 0.1000\n",
            "Epoch: 126, Loss: 0.4501, Accuracy: 84.48%, lr: 0.1000\n",
            "Epoch: 127, Loss: 0.4516, Accuracy: 84.34%, lr: 0.1000\n",
            "Epoch: 128, Loss: 0.4432, Accuracy: 84.63%, lr: 0.1000\n",
            "Epoch: 129, Loss: 0.4526, Accuracy: 84.36%, lr: 0.1000\n",
            "Epoch: 130, Loss: 0.4438, Accuracy: 84.64%, lr: 0.1000\n",
            "Epoch: 131, Loss: 0.4482, Accuracy: 84.55%, lr: 0.1000\n",
            "Epoch: 132, Loss: 0.4520, Accuracy: 84.36%, lr: 0.1000\n",
            "Epoch: 133, Loss: 0.4444, Accuracy: 84.42%, lr: 0.1000\n",
            "Epoch: 134, Loss: 0.4474, Accuracy: 84.69%, lr: 0.1000\n",
            "Epoch: 135, Loss: 0.4479, Accuracy: 84.58%, lr: 0.1000\n",
            "Epoch: 136, Loss: 0.4414, Accuracy: 84.84%, lr: 0.1000\n",
            "Epoch: 137, Loss: 0.4457, Accuracy: 84.52%, lr: 0.1000\n",
            "Epoch: 138, Loss: 0.4355, Accuracy: 84.93%, lr: 0.1000\n",
            "Epoch: 139, Loss: 0.4552, Accuracy: 84.15%, lr: 0.1000\n",
            "Epoch: 140, Loss: 0.4519, Accuracy: 84.38%, lr: 0.1000\n",
            "Epoch: 141, Loss: 0.4499, Accuracy: 84.29%, lr: 0.1000\n",
            "Epoch: 142, Loss: 0.4542, Accuracy: 84.32%, lr: 0.1000\n"
          ]
        }
      ]
    }
  ]
}